#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Dec 18 10:59:16 2018

@author: Florian Krempl
"""

import numpy as np
import pandas as pd

from keras.models import Sequential
from keras.layers import Dense
from keras.utils.vis_utils import plot_model
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
import matplotlib.pyplot as plt
import os

os.chdir('/media/shareddata/MIT/Capstone')
os.getcwd()

pd.set_option('display.expand_frame_repr', False)
seed = 1992
np.random.seed(seed)

customer_clean = pd.read_csv('data/customer_clean_route')

###############
# get dates  ##
###############

date_columns = ['ATA', 'ATD', 'ETD']
#customer_clean[date_columns] = customer_clean[date_columns].replace('-', '/', regex = True)

for column in date_columns:
    customer_clean[column] = pd.to_datetime(customer_clean[column], format =  '%Y/%m/%d')
    print(['finished converting column', column, 'to date'])


# set up model

X = customer_clean[['schedule_miss', 'mean_schedule', 'std', '1','2','3']]

y = customer_clean['y']

# standardize

num_columns = ['schedule_miss', 'mean_schedule', 'std']

scaler = StandardScaler(copy=True, with_mean=True, with_std=True)
scaler.fit(X[num_columns])
X.loc[:,num_columns] = scaler.transform(X[num_columns])

X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.30, random_state=1992)

#######################
# deep neural network #
#######################

model = Sequential()
# 1st layer
model.add(Dense(6, input_dim=6,
                kernel_initializer='normal',
                activation='relu'))
model.add(Dense(6,
                kernel_initializer='normal',
                activation='relu'))
# output layer
model.add(Dense(1, kernel_initializer='normal'))
# compile model
model.compile(loss='mean_squared_error', optimizer='adam')


###############
# plot loss  ##
###############

history = model.fit(X_train, y_train, validation_split = 0.3,
                    epochs = 2000, batch_size = 500)

print(history.history.keys())

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# train best model

model.fit(X_train, y_train, validation_split = 0.3,
                    epochs = 900, batch_size = 500)

print(model.summary())

plot_model(model, to_file='Analytics/nn_model_plot.png',
           show_shapes=True, show_layer_names=True)

##############
## test nn  ##
##############

y_hat = model.predict(X_test)

test_data = pd.DataFrame(data = {'y_hat': np.NaN,
                                 'y_test': y_test})
test_data['y_hat'] = y_hat


def print_metrics(y_hat, y_test):
    output = print('ME: ', round(np.mean(y_test-y_hat), 2), "\n",
                   'MAE: ', round(np.mean(abs(y_test-y_hat)), 2), "\n",
                   'MAPE: ', round(np.mean(abs(y_test-y_hat)/y_test), 4), "\n",
                   'RMSE: ', round(np.sqrt(np.mean((y_test-y_hat)**2)), 2), "\n"
                   ' R2: ', round(metrics.r2_score(y_true = y_test,
                                                   y_pred = y_hat),2)
                   )
    return output

print_metrics(test_data["y_hat"], test_data["y_test"])

